{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hazardous-weather",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T07:47:37.551793Z",
     "start_time": "2021-05-26T07:47:35.439944Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "clean-racing",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T07:50:32.482086Z",
     "start_time": "2021-05-26T07:50:32.456893Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a neural network class inheriting from the nn.Module\n",
    "# Call it NeuralNetwork and make, and use \"pass\" in the constructor\n",
    "# so that it doesn't give an error\n",
    "# Instantiate one instance of it in variable net\n",
    "\n",
    "net = 0\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.input_layer = nn.Linear(2, 16)\n",
    "        pass\n",
    "\n",
    "net = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "demographic-honor",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T07:51:28.420569Z",
     "start_time": "2021-05-26T07:51:28.412916Z"
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(net, NeuralNetwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "curious-syndrome",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T07:56:11.203531Z",
     "start_time": "2021-05-26T07:56:11.199729Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rewrite the NeuralNetwork class so that the constructor receives\n",
    "# as input the input_dim and num_hidden, respectively the dimension of \n",
    "# the input and the number of hidden neurons\n",
    "# use pass again\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_hidden):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.input_layer = nn.Linear(input_dim, num_hidden)\n",
    "        pass\n",
    "\n",
    "net = NeuralNetwork(10, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "recreational-macro",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T07:56:32.252906Z",
     "start_time": "2021-05-26T07:56:32.247913Z"
    }
   },
   "outputs": [],
   "source": [
    "assert NeuralNetwork(input_dim=10, num_hidden=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bigger-inclusion",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T08:04:27.491588Z",
     "start_time": "2021-05-26T08:04:27.484159Z"
    }
   },
   "outputs": [],
   "source": [
    "# Rewrite the NeuralNetwork class so that the constructor receives\n",
    "# as input the input_dim, num_hidden1 and num_hidden2, respectively the dimension of \n",
    "# the input and the number of hidden neurons for the first fully connected\n",
    "# layer and the second. Define the attributes in the constructor\n",
    "# that consists of the layers, call them fc1, fc2 and fc3 and a sigmoid.\n",
    "# use pass again. Be careful to put the dimensions in the right places!\n",
    "# Since we will do a binary classification problem, fc3 will have 1 neuron\n",
    "# as output\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, num_hidden1, num_hidden2):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, num_hidden1)\n",
    "        self.fc2 = nn.Linear(num_hidden1, num_hidden2)\n",
    "        self.fc3 = nn.Linear(num_hidden2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        layer1 = self.fc1(x)\n",
    "        act1 = self.sigmoid(layer1)\n",
    "        layer2 = self.fc2(act1)\n",
    "        act2 = self.sigmoid(layer2)\n",
    "        layer3 = self.fc3(act2)\n",
    "        out = self.sigmoid(layer3)\n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "hawaiian-noise",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-26T08:04:48.612004Z",
     "start_time": "2021-05-26T08:04:48.606773Z"
    }
   },
   "outputs": [],
   "source": [
    "net = NeuralNetwork(16, 16, 16)\n",
    "assert net.fc1\n",
    "assert net.fc2\n",
    "assert net.fc3\n",
    "assert net.sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "smart-southeast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the forward pass to make a reasonable use of the attributes\n",
    "# you defined before. Follow the same reasoning we used in class\n",
    "\n",
    "model = NeuralNetwork(2, 7, 8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "933260ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "<generator object Module.parameters at 0x00000199AAB54270>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "latest-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training a model, use the following optimizer and loss\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss = nn.BCELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "(99, 3)"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data.csv')\n",
    "df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "lesser-bunch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7077889442443848\n"
     ]
    }
   ],
   "source": [
    "# train a neural network (feel free to choose the num_hidden1 and num_hidden2)\n",
    "# on the dataset in data.csv file\n",
    "# You'll have fun with conflicting shapes and types and tensors, but\n",
    "# you'll get those errors anyway. Let's go into the wild and learn\n",
    "# by reading the errors and trying to understand them! :)\n",
    "# You can always use the provided Workbook\n",
    "\n",
    "x = df.iloc[:, :2]\n",
    "y = df.iloc[:, 2]\n",
    "x = x.to_numpy()\n",
    "y = y.to_numpy()\n",
    "x_tensor = torch.tensor(x).float()\n",
    "y_true_tensor = torch.tensor(y).float()\n",
    "y_true_tensor = y_true_tensor.reshape((99, 1))\n",
    "y_pred_tensor = model(x_tensor)\n",
    "loss_value = loss(y_pred_tensor, y_true_tensor)\n",
    "\n",
    "print(loss_value.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 0.71\n",
      "Epoch 1, loss: 0.70\n",
      "Epoch 2, loss: 0.70\n",
      "Epoch 3, loss: 0.70\n",
      "Epoch 4, loss: 0.69\n",
      "Epoch 5, loss: 0.69\n",
      "Epoch 6, loss: 0.69\n",
      "Epoch 7, loss: 0.69\n",
      "Epoch 8, loss: 0.69\n",
      "Epoch 9, loss: 0.69\n",
      "Epoch 10, loss: 0.69\n",
      "Epoch 11, loss: 0.69\n",
      "Epoch 12, loss: 0.69\n",
      "Epoch 13, loss: 0.69\n",
      "Epoch 14, loss: 0.69\n",
      "Epoch 15, loss: 0.69\n",
      "Epoch 16, loss: 0.69\n",
      "Epoch 17, loss: 0.69\n",
      "Epoch 18, loss: 0.69\n",
      "Epoch 19, loss: 0.69\n",
      "Epoch 20, loss: 0.69\n",
      "Epoch 21, loss: 0.69\n",
      "Epoch 22, loss: 0.69\n",
      "Epoch 23, loss: 0.69\n",
      "Epoch 24, loss: 0.69\n",
      "Epoch 25, loss: 0.69\n",
      "Epoch 26, loss: 0.69\n",
      "Epoch 27, loss: 0.69\n",
      "Epoch 28, loss: 0.69\n",
      "Epoch 29, loss: 0.69\n",
      "Epoch 30, loss: 0.69\n",
      "Epoch 31, loss: 0.69\n",
      "Epoch 32, loss: 0.69\n",
      "Epoch 33, loss: 0.68\n",
      "Epoch 34, loss: 0.68\n",
      "Epoch 35, loss: 0.68\n",
      "Epoch 36, loss: 0.68\n",
      "Epoch 37, loss: 0.68\n",
      "Epoch 38, loss: 0.68\n",
      "Epoch 39, loss: 0.68\n",
      "Epoch 40, loss: 0.68\n",
      "Epoch 41, loss: 0.68\n",
      "Epoch 42, loss: 0.68\n",
      "Epoch 43, loss: 0.68\n",
      "Epoch 44, loss: 0.67\n",
      "Epoch 45, loss: 0.67\n",
      "Epoch 46, loss: 0.67\n",
      "Epoch 47, loss: 0.67\n",
      "Epoch 48, loss: 0.67\n",
      "Epoch 49, loss: 0.66\n",
      "Epoch 50, loss: 0.66\n",
      "Epoch 51, loss: 0.66\n",
      "Epoch 52, loss: 0.66\n",
      "Epoch 53, loss: 0.65\n",
      "Epoch 54, loss: 0.65\n",
      "Epoch 55, loss: 0.65\n",
      "Epoch 56, loss: 0.64\n",
      "Epoch 57, loss: 0.64\n",
      "Epoch 58, loss: 0.64\n",
      "Epoch 59, loss: 0.63\n",
      "Epoch 60, loss: 0.63\n",
      "Epoch 61, loss: 0.62\n",
      "Epoch 62, loss: 0.62\n",
      "Epoch 63, loss: 0.61\n",
      "Epoch 64, loss: 0.60\n",
      "Epoch 65, loss: 0.60\n",
      "Epoch 66, loss: 0.59\n",
      "Epoch 67, loss: 0.59\n",
      "Epoch 68, loss: 0.58\n",
      "Epoch 69, loss: 0.57\n",
      "Epoch 70, loss: 0.56\n",
      "Epoch 71, loss: 0.56\n",
      "Epoch 72, loss: 0.55\n",
      "Epoch 73, loss: 0.54\n",
      "Epoch 74, loss: 0.53\n",
      "Epoch 75, loss: 0.52\n",
      "Epoch 76, loss: 0.51\n",
      "Epoch 77, loss: 0.50\n",
      "Epoch 78, loss: 0.49\n",
      "Epoch 79, loss: 0.48\n",
      "Epoch 80, loss: 0.47\n",
      "Epoch 81, loss: 0.46\n",
      "Epoch 82, loss: 0.45\n",
      "Epoch 83, loss: 0.44\n",
      "Epoch 84, loss: 0.43\n",
      "Epoch 85, loss: 0.42\n",
      "Epoch 86, loss: 0.41\n",
      "Epoch 87, loss: 0.40\n",
      "Epoch 88, loss: 0.39\n",
      "Epoch 89, loss: 0.38\n",
      "Epoch 90, loss: 0.37\n",
      "Epoch 91, loss: 0.36\n",
      "Epoch 92, loss: 0.35\n",
      "Epoch 93, loss: 0.34\n",
      "Epoch 94, loss: 0.33\n",
      "Epoch 95, loss: 0.32\n",
      "Epoch 96, loss: 0.31\n",
      "Epoch 97, loss: 0.31\n",
      "Epoch 98, loss: 0.30\n",
      "Epoch 99, loss: 0.29\n"
     ]
    }
   ],
   "source": [
    "def model_fit(x, y, model, loss, lr, num_epochs):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred_tensor = model(x_tensor)\n",
    "        loss_value = loss(y_pred_tensor, y_true_tensor)\n",
    "        print(f'Epoch {epoch}, loss: {loss_value.item():.2f}')\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "model = model_fit(x_tensor, y_true_tensor, model=model, loss=loss, lr=0.1, num_epochs=100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}